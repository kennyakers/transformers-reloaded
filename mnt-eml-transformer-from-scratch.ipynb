{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Download and import libraries","metadata":{}},{"cell_type":"code","source":"from torchtext.data.utils import get_tokenizer\nimport torch\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset\nfrom torch.nn.utils.rnn import pad_sequence\nfrom collections import Counter\nimport itertools\nfrom torch.nn import Transformer\nimport tqdm.notebook\nimport warnings\nwarnings.simplefilter(\"ignore\")\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math,copy,re\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nimport gc\nprint(torch.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-22T23:33:11.243761Z","iopub.execute_input":"2024-04-22T23:33:11.244133Z","iopub.status.idle":"2024-04-22T23:33:14.929705Z","shell.execute_reply.started":"2024-04-22T23:33:11.244105Z","shell.execute_reply":"2024-04-22T23:33:14.928805Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"2.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic=True\n\nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:33:32.911226Z","iopub.execute_input":"2024-04-22T23:33:32.911752Z","iopub.status.idle":"2024-04-22T23:33:32.919149Z","shell.execute_reply.started":"2024-04-22T23:33:32.911722Z","shell.execute_reply":"2024-04-22T23:33:32.918267Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Transformer Model (based on Attention is All you Need, Vaswani et. al.)","metadata":{}},{"cell_type":"code","source":"class Embeddings(nn.Module):\n    def __init__(self, vocab_size, embed_dim):\n        super(Embeddings, self).__init__()\n        self.vocab_size = vocab_size\n        self.embed_dim = embed_dim\n        self.embed_layer = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=self.embed_dim)\n\n    def forward(self, x):\n        out = self.embed_layer(x)\n        return out\n\nclass PositionalEmbedding(nn.Module):\n    def __init__(self, max_seq_len, embed_dim):\n        super(PositionalEmbedding, self).__init__()\n        self.embed_dim = embed_dim\n        self.max_seq_len = max_seq_len\n\n        pe = torch.zeros((self.max_seq_len, self.embed_dim))\n\n        for pos in range(self.max_seq_len):\n            for i in range(0, self.embed_dim, 2):\n                pe[pos, i] = math.sin(pos / (10000**(i/self.embed_dim)))\n                pe[pos, i+1] = math.cos(pos / (10000**(i/self.embed_dim)))\n        \n        pe = pe.unsqueeze(0)\n\n        self.register_buffer('pe', pe)\n\n    def forward(self, inp):\n        inp = inp*math.sqrt(self.embed_dim)\n        seq_len = inp.size(1)\n        inp = inp + torch.autograd.Variable(self.pe[:, :seq_len], requires_grad=False)\n        return inp\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, embed_dim=512, n_heads=8):\n        super(MultiHeadAttention, self).__init__()\n\n        self.n_heads = n_heads\n        self.embed_dim = embed_dim\n\n        self.head_dim = int(self.embed_dim/self.n_heads)\n\n        self.query_matrix = nn.Linear(self.head_dim, self.head_dim, bias=False)\n        self.key_matrix = nn.Linear(self.head_dim, self.head_dim, bias=False)\n        self.value_matrix = nn.Linear(self.head_dim, self.head_dim, bias=False)\n\n        self.out = nn.Linear(embed_dim, embed_dim)\n    \n\n    def forward(self, key, query, value, mask=None):\n        batch_size = key.size(0)\n        seq_len = key.size(1)\n\n        seq_len_query = query.size(1)\n\n        key = key.view(batch_size, seq_len, self.n_heads, self.head_dim)\n        query = query.view(batch_size, seq_len_query, self.n_heads, self.head_dim)\n        value = value.view(batch_size, seq_len, self.n_heads, self.head_dim)\n\n        k = self.key_matrix(key)\n        q = self.query_matrix(query)\n        v = self.value_matrix(value)\n        \n        k = k.transpose(1,2)\n        q = q.transpose(1,2)\n        v = v.transpose(1,2)\n\n        k_adj = k.transpose(-1,-2)\n\n        # prdt = torch.einsum(\"bhqd,bhdk->bhqk\", q, k_adj)\n        prdt = torch.matmul(q, k_adj)\n\n        if mask is not None:\n            prdt = prdt.masked_fill(mask==0, float(\"-1e20\"))\n\n        prdt = prdt/math.sqrt(self.embed_dim)\n        prdt = F.softmax(prdt, dim=-1)\n\n        # attention = torch.einsum(\"bhqk,bhkd->bhqd\", prdt, v)\n        attention = torch.matmul(prdt, v)\n\n        concat = attention.transpose(1,2).contiguous().view(batch_size, seq_len_query, self.head_dim*self.n_heads)\n\n        out = self.out(concat)\n\n        return out\n\nclass TransformerBlock(nn.Module):\n    def __init__(self, embed_dim=512, n_heads=8, expansion_factor=4):\n        super(TransformerBlock, self).__init__()\n\n        self.embed_dim = embed_dim\n        self.n_heads = n_heads\n        self.expansion_factor = expansion_factor\n\n        self.multiheadattention = MultiHeadAttention(self.embed_dim, self.n_heads)\n\n        self.norm1 = nn.LayerNorm(self.embed_dim)\n        self.dropout1 = nn.Dropout(0.1)\n        \n        self.feed_forward = nn.Sequential(\n            nn.Linear(self.embed_dim, self.embed_dim*self.expansion_factor),\n            nn.ReLU(),\n            nn.Linear(self.embed_dim*self.expansion_factor, self.embed_dim)            \n        )\n        self.norm2 = nn.LayerNorm(self.embed_dim)\n        self.dropout2 = nn.Dropout(0.1)\n\n\n    def forward(self, key, query, value, mask=None):\n        attention_out = self.multiheadattention(key, query, value, mask)  \n        attention_residual_out = attention_out + query\n        norm1_out = self.dropout1(self.norm1(attention_residual_out)) \n\n        feed_forward_out = self.feed_forward(norm1_out)\n        feed_forward_residual_out = feed_forward_out + norm1_out \n        norm2_out = self.dropout2(self.norm2(feed_forward_residual_out)) \n\n        return norm2_out\n\nclass TransformerEncoder(nn.Module):\n    def __init__(self, max_seq_len, vocab_size, embed_size=512, num_layers=6, n_heads=8, expansion_factor=4):\n        super(TransformerEncoder, self).__init__()\n\n        self.embedding_layer = Embeddings(vocab_size, embed_size)\n        self.positional_embeddings = PositionalEmbedding(max_seq_len, embed_size)\n\n        self.layers = nn.ModuleList([\n            TransformerBlock(embed_size, n_heads, expansion_factor) for i in range(num_layers)\n        ])\n\n    def forward(self, x, mask=None):\n        embed = self.embedding_layer(x)\n        out = self.positional_embeddings(embed)\n    \n        for layer in self.layers:\n            out = layer(out, out, out, mask)\n\n        return out\n\nclass DecoderBlock(nn.Module):\n    def __init__(self, embed_dim=512, n_heads=8, expansion_factor=4):\n        super(DecoderBlock, self).__init__()\n\n        self.embed_dim = embed_dim\n        self.n_heads = n_heads\n        self.expansion_factor = expansion_factor\n\n        self.transformer_block = TransformerBlock(embed_dim, n_heads, expansion_factor)\n        self.attention = MultiHeadAttention(embed_dim, n_heads)\n        self.norm = nn.LayerNorm(embed_dim)\n        self.dropout = nn.Dropout(0.1)\n    \n    def forward(self, key, value, x, tgt_mask, src_mask=None):\n        attention = self.attention(x, x, x, tgt_mask)\n        query = self.dropout(self.norm(attention + x))\n        out = self.transformer_block(key, query, value, src_mask)\n        return out\n\nclass TransformerDecoder(nn.Module):\n    def __init__(self, max_seq_len, target_vocab_size, embed_dim=512, num_layers=6, expansion_factor=4, n_heads=8):\n        super(TransformerDecoder, self).__init__()\n\n        self.word_embedding = Embeddings(target_vocab_size, embed_dim)\n        self.position_embedding = PositionalEmbedding(max_seq_len, embed_dim)\n\n        self.layers = nn.ModuleList(\n            [\n                DecoderBlock(embed_dim, expansion_factor=expansion_factor, n_heads=n_heads) \n                for _ in range(num_layers)\n            ]\n\n        )\n        self.fc_out = nn.Linear(embed_dim, target_vocab_size)\n\n    def forward(self, x, enc_out, tgt_mask, src_mask=None):\n        embed = self.word_embedding(x)\n        x = self.position_embedding(embed)\n     \n        for layer in self.layers:\n            x = layer(enc_out, enc_out, x, tgt_mask, src_mask)\n            \n        logits = self.fc_out(x)\n\n        return logits\n\nclass Transformer(nn.Module):\n    def __init__(self, embed_dim, src_vocab_size, target_vocab_size, max_seq_length, num_layers=6, expansion_factor=4, n_heads=8, device='cpu'):\n        super(Transformer, self).__init__()\n \n        self.src_pad_idx = -1\n        self.tgt_pad_idx = -1\n        self.device = device\n\n        self.encoder = TransformerEncoder(max_seq_length, \n                                          src_vocab_size, \n                                          embed_dim, \n                                          num_layers=num_layers, \n                                          expansion_factor=expansion_factor, \n                                          n_heads=n_heads)\n        \n        self.decoder = TransformerDecoder(max_seq_length, \n                                          target_vocab_size, \n                                          embed_dim, \n                                          num_layers=num_layers, \n                                          expansion_factor=expansion_factor, \n                                          n_heads=n_heads)\n        \n    \n    def make_tgt_mask(self, tgt):\n        batch_size, tgt_len = tgt.shape\n        tgt_mask = torch.tril(torch.ones((tgt_len, tgt_len))).expand(\n            batch_size, 1, tgt_len, tgt_len\n        ).bool()\n        tgt_pad_mask = (tgt.cpu() != self.tgt_pad_idx).unsqueeze(1).unsqueeze(2).bool()\n        tgt_mask = tgt_mask & tgt_pad_mask\n        return tgt_mask.to(self.device)   \n    \n    def make_pad_mask(self, inp, pad_idx):\n        mask = (inp != pad_idx).unsqueeze(1).unsqueeze(2).bool()\n        return mask.to(self.device)\n    \n    def forward(self, src, tgt):\n        tgt_mask = self.make_tgt_mask(tgt)\n        src_mask = self.make_pad_mask(src, self.src_pad_idx)\n        enc_out = self.encoder(src)\n        outputs = self.decoder(tgt, enc_out, tgt_mask, src_mask)\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:33:38.902147Z","iopub.execute_input":"2024-04-22T23:33:38.902660Z","iopub.status.idle":"2024-04-22T23:33:38.942742Z","shell.execute_reply.started":"2024-04-22T23:33:38.902632Z","shell.execute_reply":"2024-04-22T23:33:38.941759Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Loading Dataset","metadata":{}},{"cell_type":"code","source":"import random\nimport spacy\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torchtext.vocab import vocab\nfrom collections import Counter\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nfrom datasets import load_dataset\n\n# install spacy datasets\n!python3 -m spacy download de_core_news_sm\n!python3 -m spacy download en_core_web_sm\n\niwslt_dataset = load_dataset('iwslt2017', 'iwslt2017-en-de')\n\nspacy_eng = spacy.load(\"en_core_web_sm\")\nspacy_ger = spacy.load(\"de_core_news_sm\")\n\ntrain, test = iwslt_dataset['train'], iwslt_dataset['test']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, test = iwslt_dataset['train'], iwslt_dataset['test']\n# multi30k = load_dataset(\"bentrevett/multi30k\")\n# multi30k\n# train, test = multi30k['train'], multi30k['test']","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:01:51.187188Z","iopub.execute_input":"2024-04-23T00:01:51.187541Z","iopub.status.idle":"2024-04-23T00:01:51.191939Z","shell.execute_reply.started":"2024-04-23T00:01:51.187514Z","shell.execute_reply":"2024-04-23T00:01:51.190930Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"def tokenizer_ger(text):\n    return [tok.text for tok in spacy_ger.tokenizer(text)]\n\ndef tokenizer_eng(text):\n    return [tok.text for tok in spacy_eng.tokenizer(text)]","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:01:54.302930Z","iopub.execute_input":"2024-04-23T00:01:54.303837Z","iopub.status.idle":"2024-04-23T00:01:54.308749Z","shell.execute_reply.started":"2024-04-23T00:01:54.303801Z","shell.execute_reply":"2024-04-23T00:01:54.307563Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"ger_counter = Counter()\neng_counter = Counter()\nfor data in tqdm(train):\n    ger_counter.update(tokenizer_ger(data['translation']['de'].lower()))\n    eng_counter.update(tokenizer_eng(data['translation']['en'].lower()))","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:01:56.879768Z","iopub.execute_input":"2024-04-23T00:01:56.880591Z","iopub.status.idle":"2024-04-23T00:02:35.533212Z","shell.execute_reply.started":"2024-04-23T00:01:56.880555Z","shell.execute_reply":"2024-04-23T00:02:35.532231Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stderr","text":"100%|██████████| 206112/206112 [00:38<00:00, 5333.85it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"ger_vocab = vocab(ger_counter, min_freq=2, specials=(\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"))\neng_vocab = vocab(eng_counter, min_freq=2, specials=(\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"))\nger_vocab.set_default_index(ger_vocab[\"<unk>\"])\neng_vocab.set_default_index(eng_vocab[\"<unk>\"])\nprint(f\"Size of German Vocab : {len(ger_vocab)}\\n Size of English Vocab : {len(eng_vocab)}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:00:30.583046Z","iopub.execute_input":"2024-04-23T00:00:30.583728Z","iopub.status.idle":"2024-04-23T00:00:30.759260Z","shell.execute_reply.started":"2024-04-23T00:00:30.583694Z","shell.execute_reply":"2024-04-23T00:00:30.758102Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"Size of German Vocab : 7853\n Size of English Vocab : 5893\n","output_type":"stream"}]},{"cell_type":"code","source":"text_transform_eng = lambda x: [eng_vocab['<sos>']] + [eng_vocab[token.lower()] for token in tokenizer_eng(x)] + [eng_vocab['<eos>']]\ntext_transform_ger = lambda x: [ger_vocab['<sos>']] + [ger_vocab[token.lower()] for token in tokenizer_ger(x)] + [ger_vocab['<eos>']]","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:02:54.745315Z","iopub.execute_input":"2024-04-23T00:02:54.745660Z","iopub.status.idle":"2024-04-23T00:02:54.751191Z","shell.execute_reply.started":"2024-04-23T00:02:54.745634Z","shell.execute_reply":"2024-04-23T00:02:54.750209Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"def collate_batch(batch):\n    src_list, tgt_list = [], []\n    for data in batch:\n        src_list.append(torch.tensor(text_transform_ger(data['translation']['de'])))\n        tgt_list.append(torch.tensor(text_transform_eng(data['translation']['en'])))\n\n    src_list = pad_sequence(src_list, padding_value=ger_vocab['<pad>']).T\n    tgt_list = pad_sequence(tgt_list, padding_value=eng_vocab['<pad>']).T\n    \n    inp = {\n        \"src\": src_list,\n        \"tgt\": tgt_list\n    }\n\n    return inp","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:02:55.229941Z","iopub.execute_input":"2024-04-23T00:02:55.230652Z","iopub.status.idle":"2024-04-23T00:02:55.237298Z","shell.execute_reply.started":"2024-04-23T00:02:55.230618Z","shell.execute_reply":"2024-04-23T00:02:55.236265Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"markdown","source":"### Setting Training Parameters and DataLoader","metadata":{}},{"cell_type":"code","source":"num_epochs = 1\nbatch_size = 16\nlearning_rate = 1e-3\nweight_decay = 0.001\nwriter = SummaryWriter(f\"runs/loss\")\n\ntrain_dataloader = DataLoader(train, \n                              collate_fn=collate_batch,\n                              shuffle=True,\n                              batch_size=batch_size,\n                              pin_memory=True)\ntest_dataloader = DataLoader(test, \n                              collate_fn=collate_batch,\n                              shuffle=False,\n                              batch_size=batch_size,\n                              pin_memory=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntransformer_model = Transformer(embed_dim=512, \n                                src_vocab_size=len(ger_vocab), \n                                target_vocab_size=len(eng_vocab), \n                                max_seq_length=200, \n                                num_layers=6, \n                                expansion_factor=4, \n                                n_heads=8,\n                                device=device)\ntransformer_model.src_pad_idx = ger_vocab['<pad>']\ntransformer_model.tgt_pad_idx = eng_vocab['<pad>']","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:04:20.256239Z","iopub.execute_input":"2024-04-23T00:04:20.256912Z","iopub.status.idle":"2024-04-23T00:04:22.101635Z","shell.execute_reply.started":"2024-04-23T00:04:20.256880Z","shell.execute_reply":"2024-04-23T00:04:22.100623Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"total_steps = num_epochs*math.ceil(len(train)/batch_size)\n\noptimizer = torch.optim.Adam(transformer_model.parameters(), lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n                                               max_lr=learning_rate,\n                                               total_steps=total_steps,\n                                               pct_start=0.33,\n                                               div_factor=1e3,\n                                               final_div_factor=1e2)\ncriterion = nn.CrossEntropyLoss(ignore_index=eng_vocab['<pad>'])\n\ntransformer_model = transformer_model.to(device)\n\nload_model = False\nif load_model:\n    transformer_model.load_state_dict(torch.load(\"/kaggle/working/my_checkpoint.pth.tar\", map_location=device)['state_dict'])\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:04:26.109138Z","iopub.execute_input":"2024-04-23T00:04:26.109502Z","iopub.status.idle":"2024-04-23T00:04:26.167474Z","shell.execute_reply.started":"2024-04-23T00:04:26.109473Z","shell.execute_reply":"2024-04-23T00:04:26.166562Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"markdown","source":"### Beam Search Code (Naive Implementation)","metadata":{}},{"cell_type":"code","source":"def translate_seq_beam_search(model, src, device, k=2, max_len=50):\n    model.eval()\n\n    src_mask = model.make_pad_mask(src, model.src_pad_idx)\n    with torch.no_grad():\n        enc_out = model.encoder(src, src_mask)\n\n    # beam search\n\n    candidates = [(torch.LongTensor([eng_vocab['<sos>']]), 0.0)]\n\n    final_translations = []\n\n    for a in range(max_len):\n\n        input_batch = torch.concat([c[0].unsqueeze(0) for c in candidates], dim=0).to(device)\n\n        if a>0:\n            enc_out_repeat = enc_out.repeat(input_batch.shape[0], 1, 1)\n        else:\n            enc_out_repeat = enc_out\n\n        \n        with torch.no_grad():\n            output = model.decoder(input_batch, enc_out_repeat, model.make_tgt_mask(input_batch), src_mask).detach().cpu()\n        output[:, :, :2] = float(\"-1e20\")\n        output = output[:, -1, :]\n        output = F.log_softmax(output, dim=-1)\n\n\n        topk_output = torch.topk(output, k, dim=-1)\n        topk_tokens = topk_output.indices\n        topk_scores = topk_output.values\n        \n\n        new_seq = torch.concat([torch.concat([torch.vstack([c[0] for _ in range(k)]), topk_tokens[i].reshape(-1,1)], dim=-1) for i,c in enumerate(candidates)], dim=0)\n        new_scores = torch.concat([c[1] + topk_scores[i] for i,c in enumerate(candidates)], dim=0)\n\n\n        topk_new = torch.topk(new_scores, k=k).indices.tolist()\n\n        new_candidates = []\n\n        for i in range(k):\n            if new_seq[topk_new[i]][-1] == eng_vocab[\"<eos>\"] or a==max_len-1:\n                final_translations.append((new_seq[topk_new[i]].tolist(), int(new_scores[topk_new[i]])))\n            else:\n                new_candidate = (new_seq[topk_new[i]], new_scores[topk_new[i]])\n                new_candidates.append(new_candidate)\n\n        \n        if len(new_candidates) > 0:\n            candidates = new_candidates\n        else:\n            break\n    \n\n    return final_translations","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:04:35.528712Z","iopub.execute_input":"2024-04-23T00:04:35.529089Z","iopub.status.idle":"2024-04-23T00:04:35.543886Z","shell.execute_reply.started":"2024-04-23T00:04:35.529041Z","shell.execute_reply":"2024-04-23T00:04:35.543003Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"markdown","source":"### Greedy Sequence Generation","metadata":{}},{"cell_type":"code","source":"def translate_seq(model, src, device, max_len=50):\n    model.eval()\n    src_mask = model.make_pad_mask(src, model.src_pad_idx)\n    with torch.no_grad():\n        enc_src = model.encoder(src, src_mask)\n    tgt_indexes = [eng_vocab[\"<sos>\"]]\n    for i in range(max_len):\n        tgt_tensor = torch.LongTensor(tgt_indexes).unsqueeze(0).to(device)\n        tgt_mask = model.make_tgt_mask(tgt_tensor)\n        with torch.no_grad():\n            output = model.decoder(tgt_tensor, enc_src, tgt_mask, src_mask)\n        output[:, :, :2] = float(\"-1e20\")  # cannot predict <unk>, <pad> token\n        output = output[:, -1, :] # pick the last token\n        output = F.softmax(output, dim=-1)\n        pred_token = output.argmax(-1).item()\n        tgt_indexes.append(pred_token)\n        if pred_token == eng_vocab[\"<eos>\"]:\n            break\n    return tgt_indexes","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:04:38.731134Z","iopub.execute_input":"2024-04-23T00:04:38.731964Z","iopub.status.idle":"2024-04-23T00:04:38.743044Z","shell.execute_reply.started":"2024-04-23T00:04:38.731925Z","shell.execute_reply":"2024-04-23T00:04:38.742178Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"markdown","source":"### Helper Functions","metadata":{}},{"cell_type":"code","source":"def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\nclass AvgMeter:\n    def __init__(self, name=\"Metric\"):\n        self.name = name\n        self.reset()\n    \n    def reset(self):\n        self.avg, self.sum, self.count = [0]*3\n    \n    def update(self, val, count=1):\n        self.count += count\n        self.sum += val * count\n        self.avg = self.sum / self.count\n    \n    def __repr__(self):\n        text = f\"{self.name}: {self.avg:.4f}\"\n        return text","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:04:39.683575Z","iopub.execute_input":"2024-04-23T00:04:39.684288Z","iopub.status.idle":"2024-04-23T00:04:39.690870Z","shell.execute_reply.started":"2024-04-23T00:04:39.684258Z","shell.execute_reply":"2024-04-23T00:04:39.689896Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"markdown","source":"## Start Training","metadata":{}},{"cell_type":"code","source":"step = 0\nfor epoch in range(1, num_epochs+1):\n    \n    print(f\"[Epoch {epoch} / {num_epochs}]\")\n    \n    checkpoint = {\"state_dict\": transformer_model.state_dict(), \"optimizer\": optimizer.state_dict()}\n    torch.save(checkpoint, \"my_checkpoint.pth.tar\")\n    \n    loss_meter = AvgMeter()\n    transformer_model.train()\n\n    bar = tqdm(train_dataloader, total=math.ceil(len(train)/batch_size))\n\n    for idx, data in enumerate(bar):\n        \n        german = data[\"src\"].to(device)\n        english = data[\"tgt\"].to(device)\n\n        count = german.shape[0]\n\n        output = transformer_model(german, english[:,:-1])\n        \n        output = output.reshape(-1, output.shape[2])\n        english = english[:, 1:]\n        english = english.reshape(-1)\n\n        optimizer.zero_grad()\n        loss = criterion(output, english)\n        loss.backward()\n        \n        torch.nn.utils.clip_grad_norm_(transformer_model.parameters(), max_norm=1)\n\n        optimizer.step()\n        \n        if scheduler:\n            scheduler.step()\n\n        writer.add_scalar(\"Training loss\", loss, global_step=step)\n        step += 1\n        \n        loss_meter.update(loss.item(), count)\n        bar.set_postfix(loss=loss_meter.avg, lr=get_lr(optimizer), step=step)\n    \n    # Example Generation (Greedy Decode)\n    ex = test[random.randint(0, len(test))]\n    sentence = ex['translation']['de']\n    src_indexes = torch.tensor(text_transform_ger(sentence)).unsqueeze(0).to(device)    \n    translated_sentence_idx = translate_seq(transformer_model, src_indexes, device=device, max_len=50)\n    translated_sentence = [eng_vocab.get_itos()[i] for i in translated_sentence_idx]\n    print(f\"\\nExample sentence: \\n {sentence}\\n\")\n    print(f\"Original Translation : \\n {' '.join(translated_sentence[1:-1])}\\n\")\n    print(f\"Generated Translation : \\n{ex['en']}\\n\")\n    \n    del src_indexes, ex, sentence, translated_sentence_idx, translated_sentence, checkpoint\n    torch.cuda.empty_cache()\n    _ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:04:40.388586Z","iopub.execute_input":"2024-04-23T00:04:40.389217Z","iopub.status.idle":"2024-04-23T00:18:07.333977Z","shell.execute_reply.started":"2024-04-23T00:04:40.389186Z","shell.execute_reply":"2024-04-23T00:18:07.332817Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stdout","text":"[Epoch 1 / 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12882/12882 [13:26<00:00, 15.97it/s, loss=3.52, lr=1e-8, step=12882]    \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[118], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Example Generation (Greedy Decode)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m ex \u001b[38;5;241m=\u001b[39m test[random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(test))]\n\u001b[0;32m---> 46\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[43mex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtranslation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mde\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     47\u001b[0m src_indexes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(text_transform_ger(sentence))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)    \n\u001b[1;32m     48\u001b[0m translated_sentence_idx \u001b[38;5;241m=\u001b[39m translate_seq(transformer_model, src_indexes, device\u001b[38;5;241m=\u001b[39mdevice, max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n","\u001b[0;31mKeyError\u001b[0m: ('translation', 'de')"],"ename":"KeyError","evalue":"('translation', 'de')","output_type":"error"}]},{"cell_type":"markdown","source":"### Sample Beam Search Generation from Test Data","metadata":{}},{"cell_type":"code","source":"for n in range(5):\n    print(f\"Example {n+1}\\n\")\n    ex = test[random.randint(0, len(test))]\n    sentence = ex['translation']['de']\n    src_indexes = torch.tensor(text_transform_ger(sentence)).unsqueeze(0).to(device)    \n    k = 3\n    translated_sentence_ids = translate_seq_beam_search(transformer_model, src_indexes, k=k, device=device, max_len=50)\n    translated_sentence_ids = sorted(translated_sentence_ids, key= lambda x: x[1], reverse=True)\n    translations = [[eng_vocab.get_itos()[i] for i in translated_sentence[0]] for translated_sentence in translated_sentence_ids]\n    print(f\"German : {ex['translation']['de']}\")\n    print(f\"English : {ex['translation']['en']}\\n\")\n    print(f\"English Translations generated:\\n\")\n    for i in range(k):\n        for w in translations[i]:\n            if w in ['<sos>', '<eos>', '<pad>', '<unk>']:\n                continue\n            print(w, end=\" \")\n        print()\n    print(\"---------------------------------------------------------------------\\n\")\n\ndel src_indexes, ex, sentence, translated_sentence_ids, translations\ntorch.cuda.empty_cache()\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:33:41.538090Z","iopub.execute_input":"2024-04-23T00:33:41.538818Z","iopub.status.idle":"2024-04-23T00:33:45.527274Z","shell.execute_reply.started":"2024-04-23T00:33:41.538783Z","shell.execute_reply":"2024-04-23T00:33:45.526256Z"},"trusted":true},"execution_count":123,"outputs":[{"name":"stdout","text":"Example 1\n\nGerman : Wenn Sie nach dem Glück des erinnernden Selbst fragen ist es eine ganz andere Sache.\nEnglish : If you ask for the happiness of the remembering self,  it's a completely different thing.\n\nEnglish Translations generated:\n\nif you think about another one of the other , it 's the other thing . \nif you think about another one of the other , it 's a different thing . \nif you think about another one of the other , it 's the other thing to be . \n---------------------------------------------------------------------\n\nExample 2\n\nGerman : Plötzlich lässt es Lestrade zu, dieses Genie zu bewundern, das er ihm vorher verübelt hat.\nEnglish : Suddenly, Lestrade is letting himself admire this mind that he's resented.\n\nEnglish Translations generated:\n\nhe 's got to make him to make it , and he 's got to make it to make it . \nhe 's got to make him to make it , and he 's got to make it to make it to make it . \nhe 's got to make him to make it , and he 's got to make it to make it to make that . \n---------------------------------------------------------------------\n\nExample 3\n\nGerman : Jacques Cousteau kam in unsere Wohnzimmer mit seinen faszinierenden Sendungen, die uns Tiere und Orte und eine Welt voller Wunder zeigten, die wir uns vorher nie hätten vorstellen können.\nEnglish : Jacques Cousteau was coming into our living rooms  with his amazing specials that showed us  animals and places and a wondrous world  that we could never really have previously imagined.\n\nEnglish Translations generated:\n\nso we can take the world in the world , and we can use the same world , and we can use the same world , and we can use the same world in the world . \nso we can take the world in the world , and we can use the same world , and we can use the same world , and we can use the same world in the world , and the world of us . \nso we can take the world in the world , and we can use the same world , and we can use the same world , and we can use the same world in the world , and the world of our lives . \n---------------------------------------------------------------------\n\nExample 4\n\nGerman : Danke.\nEnglish : Thank you.\n\nEnglish Translations generated:\n\nno . \nit 's called . \nit 's really . \n---------------------------------------------------------------------\n\nExample 5\n\nGerman : Und ich bediente die mechanischen Besen und pflügte den Schnee.\nEnglish : And I operated the mechanical brooms and I plowed the snow.\n\nEnglish Translations generated:\n\nand i got the white pictures , and i got the red . \nand i got the white pictures , and i got the white . \nand i got the white pictures , and i got the white and the white . \n---------------------------------------------------------------------\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Calculating Bleu Score","metadata":{}},{"cell_type":"code","source":"from torchtext.data.metrics import bleu_score\n\ndef calculate_bleu(data, model, device, max_len=50):\n    tgts = []\n    preds = []\n    for datum in tqdm(data):\n        src = datum['translation'][\"de\"]\n        tgt = datum['translation'][\"en\"]\n        src_idx = torch.tensor(text_transform_ger(src)).unsqueeze(0).to(device)\n        pred_tgt = translate_seq(model, src_idx, device, max_len)\n        pred_tgt = pred_tgt[1:-1]\n        pred_sent = [eng_vocab.get_itos()[i] for i in pred_tgt]\n        preds.append(pred_sent)\n        tgts.append([tokenizer_eng(tgt.lower())])\n\n    return bleu_score(preds, tgts) ","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:34:00.325281Z","iopub.execute_input":"2024-04-23T00:34:00.326326Z","iopub.status.idle":"2024-04-23T00:34:00.335707Z","shell.execute_reply.started":"2024-04-23T00:34:00.326289Z","shell.execute_reply":"2024-04-23T00:34:00.334656Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"bleu = calculate_bleu(test, transformer_model, device)\nprint(\"BLEU Score Achieved :\", bleu)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:34:02.254788Z","iopub.execute_input":"2024-04-23T00:34:02.255463Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":" 88%|████████▊ | 7125/8079 [21:37<02:27,  6.47it/s]","output_type":"stream"}]}]}