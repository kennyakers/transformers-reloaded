{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Download and import libraries","metadata":{}},{"cell_type":"code","source":"from torchtext.data.utils import get_tokenizer\nimport torch\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset\nfrom torch.nn.utils.rnn import pad_sequence\nfrom collections import Counter\nimport itertools\nfrom torch.nn import Transformer\nimport tqdm.notebook\nimport warnings\nwarnings.simplefilter(\"ignore\")\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math,copy,re\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nimport gc\nimport torch\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torch.utils.data import DataLoader\nprint(torch.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-24T21:41:21.618954Z","iopub.execute_input":"2024-04-24T21:41:21.619288Z","iopub.status.idle":"2024-04-24T21:41:38.832456Z","shell.execute_reply.started":"2024-04-24T21:41:21.619260Z","shell.execute_reply":"2024-04-24T21:41:38.831503Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-04-24 21:41:29.415069: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-24 21:41:29.415186: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-24 21:41:29.554438: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"2.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic=True\n\nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:41:38.834134Z","iopub.execute_input":"2024-04-24T21:41:38.834697Z","iopub.status.idle":"2024-04-24T21:41:38.843874Z","shell.execute_reply.started":"2024-04-24T21:41:38.834670Z","shell.execute_reply":"2024-04-24T21:41:38.842749Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Transformer Model (based on Attention is All you Need, Vaswani et. al.)","metadata":{}},{"cell_type":"code","source":"class Embeddings(nn.Module):\n    def __init__(self, vocab_size, embed_dim):\n        super(Embeddings, self).__init__()\n        self.vocab_size = vocab_size\n        self.embed_dim = embed_dim\n        self.embed_layer = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=self.embed_dim)\n\n    def forward(self, x):\n        out = self.embed_layer(x)\n        return out\n\nclass PositionalEmbedding(nn.Module):\n    def __init__(self, max_seq_len, embed_dim):\n        super(PositionalEmbedding, self).__init__()\n        self.embed_dim = embed_dim\n        self.max_seq_len = max_seq_len\n\n        pe = torch.zeros((self.max_seq_len, self.embed_dim))\n\n        for pos in range(self.max_seq_len):\n            for i in range(0, self.embed_dim, 2):\n                pe[pos, i] = math.sin(pos / (10000**(i/self.embed_dim)))\n                pe[pos, i+1] = math.cos(pos / (10000**(i/self.embed_dim)))\n        \n        pe = pe.unsqueeze(0)\n\n        self.register_buffer('pe', pe)\n\n    def forward(self, inp):\n        inp = inp*math.sqrt(self.embed_dim)\n        seq_len = inp.size(1)\n        inp = inp + torch.autograd.Variable(self.pe[:, :seq_len], requires_grad=False)\n        return inp\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, embed_dim=512, n_heads=8):\n        super(MultiHeadAttention, self).__init__()\n\n        self.n_heads = n_heads\n        self.embed_dim = embed_dim\n\n        self.head_dim = int(self.embed_dim/self.n_heads)\n\n        self.query_matrix = nn.Linear(self.head_dim, self.head_dim, bias=False)\n        self.key_matrix = nn.Linear(self.head_dim, self.head_dim, bias=False)\n        self.value_matrix = nn.Linear(self.head_dim, self.head_dim, bias=False)\n\n        self.out = nn.Linear(embed_dim, embed_dim)\n    \n\n    def forward(self, key, query, value, mask=None):\n        batch_size = key.size(0)\n        seq_len = key.size(1)\n\n        seq_len_query = query.size(1)\n\n        key = key.view(batch_size, seq_len, self.n_heads, self.head_dim)\n        query = query.view(batch_size, seq_len_query, self.n_heads, self.head_dim)\n        value = value.view(batch_size, seq_len, self.n_heads, self.head_dim)\n\n        k = self.key_matrix(key)\n        q = self.query_matrix(query)\n        v = self.value_matrix(value)\n        \n        k = k.transpose(1,2)\n        q = q.transpose(1,2)\n        v = v.transpose(1,2)\n\n        k_adj = k.transpose(-1,-2)\n\n        # prdt = torch.einsum(\"bhqd,bhdk->bhqk\", q, k_adj)\n        prdt = torch.matmul(q, k_adj)\n\n        if mask is not None:\n            prdt = prdt.masked_fill(mask==0, float(\"-1e20\"))\n\n        prdt = prdt/math.sqrt(self.embed_dim)\n        prdt = F.softmax(prdt, dim=-1)\n\n        # attention = torch.einsum(\"bhqk,bhkd->bhqd\", prdt, v)\n        attention = torch.matmul(prdt, v)\n\n        concat = attention.transpose(1,2).contiguous().view(batch_size, seq_len_query, self.head_dim*self.n_heads)\n\n        out = self.out(concat)\n\n        return out\n\nclass TransformerBlock(nn.Module):\n    def __init__(self, embed_dim=512, n_heads=8, expansion_factor=4):\n        super(TransformerBlock, self).__init__()\n\n        self.embed_dim = embed_dim\n        self.n_heads = n_heads\n        self.expansion_factor = expansion_factor\n\n        self.multiheadattention = MultiHeadAttention(self.embed_dim, self.n_heads)\n\n        self.norm1 = nn.LayerNorm(self.embed_dim)\n        self.dropout1 = nn.Dropout(0.1)\n        \n        self.feed_forward = nn.Sequential(\n            nn.Linear(self.embed_dim, self.embed_dim*self.expansion_factor),\n            nn.ReLU(),\n            nn.Linear(self.embed_dim*self.expansion_factor, self.embed_dim)            \n        )\n        self.norm2 = nn.LayerNorm(self.embed_dim)\n        self.dropout2 = nn.Dropout(0.1)\n\n\n    def forward(self, key, query, value, mask=None):\n        attention_out = self.multiheadattention(key, query, value, mask)  \n        attention_residual_out = attention_out + query\n        norm1_out = self.dropout1(self.norm1(attention_residual_out)) \n\n        feed_forward_out = self.feed_forward(norm1_out)\n        feed_forward_residual_out = feed_forward_out + norm1_out \n        norm2_out = self.dropout2(self.norm2(feed_forward_residual_out)) \n\n        return norm2_out\n\nclass TransformerEncoder(nn.Module):\n    def __init__(self, max_seq_len, vocab_size, embed_size=512, num_layers=6, n_heads=8, expansion_factor=4):\n        super(TransformerEncoder, self).__init__()\n\n        self.embedding_layer = Embeddings(vocab_size, embed_size)\n        self.positional_embeddings = PositionalEmbedding(max_seq_len, embed_size)\n\n        self.layers = nn.ModuleList([\n            TransformerBlock(embed_size, n_heads, expansion_factor) for i in range(num_layers)\n        ])\n\n    def forward(self, x, mask=None):\n        embed = self.embedding_layer(x)\n        out = self.positional_embeddings(embed)\n    \n        for layer in self.layers:\n            out = layer(out, out, out, mask)\n\n        return out\n\nclass DecoderBlock(nn.Module):\n    def __init__(self, embed_dim=512, n_heads=8, expansion_factor=4):\n        super(DecoderBlock, self).__init__()\n\n        self.embed_dim = embed_dim\n        self.n_heads = n_heads\n        self.expansion_factor = expansion_factor\n\n        self.transformer_block = TransformerBlock(embed_dim, n_heads, expansion_factor)\n        self.attention = MultiHeadAttention(embed_dim, n_heads)\n        self.norm = nn.LayerNorm(embed_dim)\n        self.dropout = nn.Dropout(0.1)\n    \n    def forward(self, key, value, x, tgt_mask, src_mask=None):\n        attention = self.attention(x, x, x, tgt_mask)\n        query = self.dropout(self.norm(attention + x))\n        out = self.transformer_block(key, query, value, src_mask)\n        return out\n\nclass TransformerDecoder(nn.Module):\n    def __init__(self, max_seq_len, target_vocab_size, embed_dim=512, num_layers=6, expansion_factor=4, n_heads=8):\n        super(TransformerDecoder, self).__init__()\n\n        self.word_embedding = Embeddings(target_vocab_size, embed_dim)\n        self.position_embedding = PositionalEmbedding(max_seq_len, embed_dim)\n\n        self.layers = nn.ModuleList(\n            [\n                DecoderBlock(embed_dim, expansion_factor=expansion_factor, n_heads=n_heads) \n                for _ in range(num_layers)\n            ]\n\n        )\n        self.fc_out = nn.Linear(embed_dim, target_vocab_size)\n\n    def forward(self, x, enc_out, tgt_mask, src_mask=None):\n        embed = self.word_embedding(x)\n        x = self.position_embedding(embed)\n     \n        for layer in self.layers:\n            x = layer(enc_out, enc_out, x, tgt_mask, src_mask)\n            \n        logits = self.fc_out(x)\n\n        return logits\n\nclass Transformer(nn.Module):\n    def __init__(self, embed_dim, src_vocab_size, target_vocab_size, max_seq_length, num_layers=6, expansion_factor=4, n_heads=8, device='cpu'):\n        super(Transformer, self).__init__()\n \n        self.src_pad_idx = -1\n        self.tgt_pad_idx = -1\n        self.device = device\n\n        self.encoder = TransformerEncoder(max_seq_length, \n                                          src_vocab_size, \n                                          embed_dim, \n                                          num_layers=num_layers, \n                                          expansion_factor=expansion_factor, \n                                          n_heads=n_heads)\n        \n        self.decoder = TransformerDecoder(max_seq_length, \n                                          target_vocab_size, \n                                          embed_dim, \n                                          num_layers=num_layers, \n                                          expansion_factor=expansion_factor, \n                                          n_heads=n_heads)\n        \n    \n    def make_tgt_mask(self, tgt):\n        batch_size, tgt_len = tgt.shape\n        tgt_mask = torch.tril(torch.ones((tgt_len, tgt_len))).expand(\n            batch_size, 1, tgt_len, tgt_len\n        ).bool()\n        tgt_pad_mask = (tgt.cpu() != self.tgt_pad_idx).unsqueeze(1).unsqueeze(2).bool()\n        tgt_mask = tgt_mask & tgt_pad_mask\n        return tgt_mask.to(self.device)   \n    \n    def make_pad_mask(self, inp, pad_idx):\n        mask = (inp != pad_idx).unsqueeze(1).unsqueeze(2).bool()\n        return mask.to(self.device)\n    \n    def forward(self, src, tgt):\n        tgt_mask = self.make_tgt_mask(tgt)\n        src_mask = self.make_pad_mask(src, self.src_pad_idx)\n        enc_out = self.encoder(src)\n        outputs = self.decoder(tgt, enc_out, tgt_mask, src_mask)\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:41:38.845808Z","iopub.execute_input":"2024-04-24T21:41:38.846484Z","iopub.status.idle":"2024-04-24T21:41:38.891081Z","shell.execute_reply.started":"2024-04-24T21:41:38.846424Z","shell.execute_reply":"2024-04-24T21:41:38.890104Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Loading Dataset","metadata":{}},{"cell_type":"code","source":"import random\nimport spacy\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torchtext.vocab import vocab\nfrom collections import Counter\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nfrom datasets import load_dataset\n\n# install spacy datasets\n!python3 -m spacy download de_core_news_sm\n!python3 -m spacy download en_core_web_sm\n\niwslt_dataset = load_dataset('iwslt2017', 'iwslt2017-en-de')\n\nspacy_eng = spacy.load(\"en_core_web_sm\")\nspacy_ger = spacy.load(\"de_core_news_sm\")\n\ntrain, test = iwslt_dataset['train'], iwslt_dataset['test']","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:42:06.929373Z","iopub.execute_input":"2024-04-24T21:42:06.929765Z","iopub.status.idle":"2024-04-24T21:42:51.570658Z","shell.execute_reply.started":"2024-04-24T21:42:06.929738Z","shell.execute_reply":"2024-04-24T21:42:51.569664Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting de-core-news-sm==3.7.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from de-core-news-sm==3.7.0) (3.7.3)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.2)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.3)\nInstalling collected packages: de-core-news-sm\nSuccessfully installed de-core-news-sm-3.7.0\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('de_core_news_sm')\nCollecting en-core-web-sm==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.3)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenizer_ger(text):\n    return [tok.text for tok in spacy_ger.tokenizer(text)]\n\ndef tokenizer_eng(text):\n    return [tok.text for tok in spacy_eng.tokenizer(text)]","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:44:51.530383Z","iopub.execute_input":"2024-04-24T21:44:51.531066Z","iopub.status.idle":"2024-04-24T21:44:51.536017Z","shell.execute_reply.started":"2024-04-24T21:44:51.531034Z","shell.execute_reply":"2024-04-24T21:44:51.535045Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"ger_counter = Counter()\neng_counter = Counter()\nfor data in tqdm(train):\n    ger_counter.update(tokenizer_ger(data['translation']['de'].lower()))\n    eng_counter.update(tokenizer_eng(data['translation']['en'].lower()))","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:42:51.579444Z","iopub.execute_input":"2024-04-24T21:42:51.579778Z","iopub.status.idle":"2024-04-24T21:43:52.167397Z","shell.execute_reply.started":"2024-04-24T21:42:51.579748Z","shell.execute_reply":"2024-04-24T21:43:52.166503Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████| 206112/206112 [01:00<00:00, 3402.64it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"ger_vocab = vocab(ger_counter, min_freq=2, specials=(\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"))\neng_vocab = vocab(eng_counter, min_freq=2, specials=(\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"))\nger_vocab.set_default_index(ger_vocab[\"<unk>\"])\neng_vocab.set_default_index(eng_vocab[\"<unk>\"])\nprint(f\"Size of German Vocab : {len(ger_vocab)}\\n Size of English Vocab : {len(eng_vocab)}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:43:52.169487Z","iopub.execute_input":"2024-04-24T21:43:52.169793Z","iopub.status.idle":"2024-04-24T21:43:52.380193Z","shell.execute_reply.started":"2024-04-24T21:43:52.169768Z","shell.execute_reply":"2024-04-24T21:43:52.379280Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Size of German Vocab : 58546\n Size of English Vocab : 33660\n","output_type":"stream"}]},{"cell_type":"code","source":"text_transform_eng = lambda x: [eng_vocab['<sos>']] + [eng_vocab[token.lower()] for token in tokenizer_eng(x)] + [eng_vocab['<eos>']]\ntext_transform_ger = lambda x: [ger_vocab['<sos>']] + [ger_vocab[token.lower()] for token in tokenizer_ger(x)] + [ger_vocab['<eos>']]","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:43:52.381343Z","iopub.execute_input":"2024-04-24T21:43:52.381636Z","iopub.status.idle":"2024-04-24T21:43:52.391393Z","shell.execute_reply.started":"2024-04-24T21:43:52.381612Z","shell.execute_reply":"2024-04-24T21:43:52.390463Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def collate_batch(batch):\n    src_list, tgt_list = [], []\n    for data in batch:\n        src_list.append(torch.tensor(text_transform_eng(data['translation']['en'])))\n        tgt_list.append(torch.tensor(text_transform_ger(data['translation']['de'])))\n\n    src_list = pad_sequence(src_list, padding_value=eng_vocab['<pad>']).T\n    tgt_list = pad_sequence(tgt_list, padding_value=ger_vocab['<pad>']).T\n    \n    inp = {\n        \"src\": src_list,\n        \"tgt\": tgt_list\n    }\n\n    return inp","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:43:52.392392Z","iopub.execute_input":"2024-04-24T21:43:52.392681Z","iopub.status.idle":"2024-04-24T21:43:52.404031Z","shell.execute_reply.started":"2024-04-24T21:43:52.392658Z","shell.execute_reply":"2024-04-24T21:43:52.403176Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Setting Training Parameters and DataLoader","metadata":{}},{"cell_type":"code","source":"num_epochs = 1\nbatch_size = 16\nlearning_rate = 1e-3\nweight_decay = 0.001\nwriter = SummaryWriter(f\"runs/loss\")\n\ntrain_dataloader = DataLoader(train, \n                              collate_fn=collate_batch,\n                              shuffle=True,\n                              batch_size=batch_size,\n                              pin_memory=True)\ntest_dataloader = DataLoader(test, \n                              collate_fn=collate_batch,\n                              shuffle=False,\n                              batch_size=batch_size,\n                              pin_memory=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntransformer_model = Transformer(embed_dim=512, \n                                src_vocab_size=len(eng_vocab), \n                                target_vocab_size=len(ger_vocab), \n                                max_seq_length=200, \n                                num_layers=6, \n                                expansion_factor=4, \n                                n_heads=8,\n                                device=device)\ntransformer_model.src_pad_idx = eng_vocab['<pad>']\ntransformer_model.tgt_pad_idx = ger_vocab['<pad>']","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:43:52.405061Z","iopub.execute_input":"2024-04-24T21:43:52.405316Z","iopub.status.idle":"2024-04-24T21:43:55.142912Z","shell.execute_reply.started":"2024-04-24T21:43:52.405295Z","shell.execute_reply":"2024-04-24T21:43:55.141896Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"total_steps = num_epochs*math.ceil(len(train)/batch_size)\n\noptimizer = torch.optim.Adam(transformer_model.parameters(), lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n                                               max_lr=learning_rate,\n                                               total_steps=total_steps,\n                                               pct_start=0.33,\n                                               div_factor=1e3,\n                                               final_div_factor=1e2)\ncriterion = nn.CrossEntropyLoss(ignore_index=ger_vocab['<pad>'])\n\ntransformer_model = transformer_model.to(device)\n\nload_model = False\nif load_model:\n    transformer_model.load_state_dict(torch.load(\"/kaggle/working/my_checkpoint.pth.tar\", map_location=device)['state_dict'])","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:43:55.145263Z","iopub.execute_input":"2024-04-24T21:43:55.145664Z","iopub.status.idle":"2024-04-24T21:43:56.103327Z","shell.execute_reply.started":"2024-04-24T21:43:55.145629Z","shell.execute_reply":"2024-04-24T21:43:56.102471Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Beam Search Code (Naive Implementation)","metadata":{}},{"cell_type":"code","source":"def translate_seq_beam_search(model, src, device, k=2, max_len=50):\n    model.eval()\n\n    src_mask = model.make_pad_mask(src, model.src_pad_idx)\n    with torch.no_grad():\n        enc_out = model.encoder(src, src_mask)\n\n    # beam search\n\n    candidates = [(torch.LongTensor([ger_vocab['<sos>']]), 0.0)]\n\n    final_translations = []\n\n    for a in range(max_len):\n\n        input_batch = torch.concat([c[0].unsqueeze(0) for c in candidates], dim=0).to(device)\n\n        if a>0:\n            enc_out_repeat = enc_out.repeat(input_batch.shape[0], 1, 1)\n        else:\n            enc_out_repeat = enc_out\n\n        \n        with torch.no_grad():\n            output = model.decoder(input_batch, enc_out_repeat, model.make_tgt_mask(input_batch), src_mask).detach().cpu()\n        output[:, :, :2] = float(\"-1e20\")\n        output = output[:, -1, :]\n        output = F.log_softmax(output, dim=-1)\n\n\n        topk_output = torch.topk(output, k, dim=-1)\n        topk_tokens = topk_output.indices\n        topk_scores = topk_output.values\n        \n\n        new_seq = torch.concat([torch.concat([torch.vstack([c[0] for _ in range(k)]), topk_tokens[i].reshape(-1,1)], dim=-1) for i,c in enumerate(candidates)], dim=0)\n        new_scores = torch.concat([c[1] + topk_scores[i] for i,c in enumerate(candidates)], dim=0)\n\n\n        topk_new = torch.topk(new_scores, k=k).indices.tolist()\n\n        new_candidates = []\n\n        for i in range(k):\n            if new_seq[topk_new[i]][-1] == ger_vocab[\"<eos>\"] or a==max_len-1:\n                final_translations.append((new_seq[topk_new[i]].tolist(), int(new_scores[topk_new[i]])))\n            else:\n                new_candidate = (new_seq[topk_new[i]], new_scores[topk_new[i]])\n                new_candidates.append(new_candidate)\n\n        \n        if len(new_candidates) > 0:\n            candidates = new_candidates\n        else:\n            break\n    \n\n    return final_translations","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:43:56.104531Z","iopub.execute_input":"2024-04-24T21:43:56.104834Z","iopub.status.idle":"2024-04-24T21:43:56.119410Z","shell.execute_reply.started":"2024-04-24T21:43:56.104799Z","shell.execute_reply":"2024-04-24T21:43:56.118562Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Greedy Sequence Generation","metadata":{}},{"cell_type":"code","source":"def translate_seq(model, src, device, max_len=50):\n    model.eval()\n    src_mask = model.make_pad_mask(src, model.src_pad_idx)\n    with torch.no_grad():\n        enc_src = model.encoder(src, src_mask)\n    tgt_indexes = [ger_vocab[\"<sos>\"]]\n    for i in range(max_len):\n        tgt_tensor = torch.LongTensor(tgt_indexes).unsqueeze(0).to(device)\n        tgt_mask = model.make_tgt_mask(tgt_tensor)\n        with torch.no_grad():\n            output = model.decoder(tgt_tensor, enc_src, tgt_mask, src_mask)\n        output[:, :, :2] = float(\"-1e20\")  # cannot predict <unk>, <pad> token\n        output = output[:, -1, :] # pick the last token\n        output = F.softmax(output, dim=-1)\n        pred_token = output.argmax(-1).item()\n        tgt_indexes.append(pred_token)\n        if pred_token == ger_vocab[\"<eos>\"]:\n            break\n    return tgt_indexes","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:43:56.122625Z","iopub.execute_input":"2024-04-24T21:43:56.122995Z","iopub.status.idle":"2024-04-24T21:43:56.133402Z","shell.execute_reply.started":"2024-04-24T21:43:56.122972Z","shell.execute_reply":"2024-04-24T21:43:56.132599Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Helper Functions","metadata":{}},{"cell_type":"code","source":"def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\nclass AvgMeter:\n    def __init__(self, name=\"Metric\"):\n        self.name = name\n        self.reset()\n    \n    def reset(self):\n        self.avg, self.sum, self.count = [0]*3\n    \n    def update(self, val, count=1):\n        self.count += count\n        self.sum += val * count\n        self.avg = self.sum / self.count\n    \n    def __repr__(self):\n        text = f\"{self.name}: {self.avg:.4f}\"\n        return text","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:43:56.134516Z","iopub.execute_input":"2024-04-24T21:43:56.134807Z","iopub.status.idle":"2024-04-24T21:43:56.147585Z","shell.execute_reply.started":"2024-04-24T21:43:56.134784Z","shell.execute_reply":"2024-04-24T21:43:56.146854Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Start Training","metadata":{}},{"cell_type":"code","source":"step = 0\nfor epoch in range(1, num_epochs+1):\n    \n    print(f\"[Epoch {epoch} / {num_epochs}]\")\n    \n    loss_meter = AvgMeter()\n    transformer_model.train()\n\n    bar = tqdm(train_dataloader, total=math.ceil(len(train)/batch_size))\n\n    for idx, data in enumerate(bar):\n        \n        english = data[\"src\"].to(device)\n        german = data[\"tgt\"].to(device)\n\n        count = english.shape[0]\n\n        output = transformer_model(english, german[:,:-1])\n        \n        output = output.reshape(-1, output.shape[2])\n        german = german[:, 1:]\n        german = german.reshape(-1)\n\n        optimizer.zero_grad()\n        loss = criterion(output, german)\n        loss.backward()\n        \n        torch.nn.utils.clip_grad_norm_(transformer_model.parameters(), max_norm=1)\n\n        optimizer.step()\n        \n        if scheduler:\n            scheduler.step()\n\n        writer.add_scalar(\"Training loss\", loss, global_step=step)\n        step += 1\n        \n        loss_meter.update(loss.item(), count)\n        bar.set_postfix(loss=loss_meter.avg, lr=get_lr(optimizer), step=step)\n    \n    checkpoint = {\"state_dict\": transformer_model.state_dict(), \"optimizer\": optimizer.state_dict()}\n    torch.save(checkpoint, \"my_checkpoint.pth.tar\")\n    \n    # Example Generation (Greedy Decode)\n    ex = test[random.randint(0, len(test))]\n    sentence = ex['translation']['en']\n    src_indexes = torch.tensor(text_transform_eng(sentence)).unsqueeze(0).to(device)    \n    translated_sentence_idx = translate_seq(transformer_model, src_indexes, device=device, max_len=50)\n    translated_sentence = [ger_vocab.get_itos()[i] for i in translated_sentence_idx]\n    print(f\"\\nExample sentence: \\n {sentence}\\n\")\n    print(f\"Original Translation : \\n{ex['translation']['de']}\\n\")\n    print(f\"Generated Translation : \\n {' '.join(translated_sentence[1:-1])}\\n\")\n    \n    del src_indexes, ex, sentence, translated_sentence_idx, translated_sentence, checkpoint\n    torch.cuda.empty_cache()\n    _ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:02:57.530933Z","iopub.execute_input":"2024-04-24T21:02:57.531385Z","iopub.status.idle":"2024-04-24T21:24:20.766589Z","shell.execute_reply.started":"2024-04-24T21:02:57.531349Z","shell.execute_reply":"2024-04-24T21:24:20.765411Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"[Epoch 1 / 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12882/12882 [21:19<00:00, 10.07it/s, loss=5.12, lr=1e-8, step=12882]    \n","output_type":"stream"},{"name":"stdout","text":"\nExample sentence: \n Here's me on the same day as this shoot.\n\nOriginal Translation : \n hier ist die zeit , die mich auf der nacht auf dem tag .\n\nGenerated Translation : \nDas bin ich am Tag dieses Shootings.\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Sample Beam Search Generation from Test Data","metadata":{}},{"cell_type":"code","source":"load_model = True\nif load_model:\n    transformer_model.load_state_dict(torch.load(\"/kaggle/working/my_checkpoint.pth.tar\", map_location=device)['state_dict'])","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:43:56.148658Z","iopub.execute_input":"2024-04-24T21:43:56.149704Z","iopub.status.idle":"2024-04-24T21:43:57.289284Z","shell.execute_reply.started":"2024-04-24T21:43:56.149681Z","shell.execute_reply":"2024-04-24T21:43:57.288268Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Function to compute loss on the test set\ndef evaluate_model(model, dataloader, device, criterion):\n    model.eval()  # Set the model to evaluation mode\n    total_loss = 0\n    total_items = 0\n    bar = tqdm(dataloader, total=math.ceil(len(train)/batch_size))\n    with torch.no_grad():  # No need to track gradients for evaluation\n        for idx, data in enumerate(bar):\n            src = data[\"src\"]\n            tgt = data[\"tgt\"]\n            src = src.to(device)\n            tgt_input = tgt[:, :-1].to(device)\n            tgt_output = tgt[:, 1:].to(device)  # Shift for teacher forcing\n            \n            # Forward pass\n            output = model(src, tgt_input)\n            output_dim = output.shape[-1]\n            \n            # Reshape output for calculating loss\n            output = output.contiguous().view(-1, output_dim)\n            tgt_output = tgt_output.contiguous().view(-1)\n            \n            # Calculate loss\n            loss = criterion(output, tgt_output)\n            total_loss += loss.item()\n            total_items += tgt_output.shape[0]\n\n    return total_loss / total_items\n\n# Define the loss criterion, typically CrossEntropyLoss for classification tasks\ncriterion = torch.nn.CrossEntropyLoss(ignore_index=transformer_model.tgt_pad_idx)\n\n# Example usage\ntest_loss = evaluate_model(transformer_model, test_dataloader, device, criterion)\nprint(f\"Average loss on the test set: {test_loss:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:29:41.792261Z","iopub.execute_input":"2024-04-24T21:29:41.792645Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  4%|▎         | 467/12882 [00:13<06:00, 34.44it/s]","output_type":"stream"}]},{"cell_type":"code","source":"for n in range(5):\n    print(f\"Example {n+1}\\n\")\n    ex = test[random.randint(0, len(test))]\n    sentence = ex['translation']['en']\n    src_indexes = torch.tensor(text_transform_eng(sentence)).unsqueeze(0).to(device)    \n    k = 3\n    translated_sentence_ids = translate_seq_beam_search(transformer_model, src_indexes, k=k, device=device, max_len=50)\n    translated_sentence_ids = sorted(translated_sentence_ids, key= lambda x: x[1], reverse=True)\n    translations = [[ger_vocab.get_itos()[i] for i in translated_sentence[0]] for translated_sentence in translated_sentence_ids]\n    print(f\"English : {ex['translation']['en']}\\n\")\n    print(f\"German : {ex['translation']['de']}\")\n    print(f\"German Translations generated:\\n\")\n    for i in range(k):\n        for w in translations[i]:\n            if w in ['<sos>', '<eos>', '<pad>', '<unk>']:\n                continue\n            print(w, end=\" \")\n        print()\n    print(\"---------------------------------------------------------------------\\n\")\n\ndel src_indexes, ex, sentence, translated_sentence_ids, translations\ntorch.cuda.empty_cache()\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:43:57.290649Z","iopub.execute_input":"2024-04-24T21:43:57.291010Z","iopub.status.idle":"2024-04-24T21:44:21.432336Z","shell.execute_reply.started":"2024-04-24T21:43:57.290976Z","shell.execute_reply":"2024-04-24T21:44:21.431276Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Example 1\n\nEnglish : Here's me on the same day as this shoot.\n\nGerman : Das bin ich am Tag dieses Shootings.\nGerman Translations generated:\n\nhier ist die zeit , die mich auf der nacht auf dem tag . \nhier ist die zeit , die mich auf dem tag auf dem tag . \nhier ist die zeit , die mich auf der nacht auf dem tag zu sehen . \n---------------------------------------------------------------------\n\nExample 2\n\nEnglish : After the success of \"Titanic,\"  I said, \"OK, I'm going to park my day job  as a Hollywood movie maker,  and I'm going to go be a full-time explorer for a while.\"\n\nGerman : Nach dem Erfolg von \"Titanic\" sagte ich mir, \"Okay, ich will meinen Hauptberuf als Filmemacher in Hollywood auf Eis legen und werde für eine Weile Vollzeit-Forscher.\"\nGerman Translations generated:\n\nals ich nach einem moment ging , sagte ich : \" ich werde mich auf der bühne gehen , ich werde ein kind sein . \"   ich werde mich mit der zeit gehen , und ich werde ein kind sein . \" \nals ich nach einem moment ging , sagte ich : \" ich werde mich auf der bühne gehen , ich werde ein kind sein . \"   ich werde mich mit der zeit gehen , und ich werde ein bisschen zeit sein , als der zeit zu hause zu hause \nals ich nach einem moment ging , sagte ich : \" ich werde mich auf der bühne gehen , ich werde ein kind sein . \"   ich werde mich mit der zeit gehen , und ich werde ein bisschen zeit sein , als der zeit zu hause , und \n---------------------------------------------------------------------\n\nExample 3\n\nEnglish : We didn't have polio in this country yesterday.\n\nGerman : Wir hatten in diesem Land gestern keine Kinderlähmung.\nGerman Translations generated:\n\nwir haben nicht in diesem land in indien gemacht . \nwir haben nicht in diesem jahr in indien geboren . \nwir haben nicht in diesem jahr in amerika geboren . \n---------------------------------------------------------------------\n\nExample 4\n\nEnglish : According to the Bureau of Labor Statistics, sanitation work is one of the 10 most dangerous occupations in the country, and I learned why.\n\nGerman : Nach Statistiken des Arbeitsministeriums ist der Beruf in der Stadtreinigung unter den 10 gefährlichsten Jobs im Land. Und ich lernte, warum.\nGerman Translations generated:\n\nals ich vor drei jahren begann , habe ich die meisten von den meisten von den meisten der meisten der meisten der meisten der meisten der meisten der meisten der meisten der meisten der meisten der meisten von heute in der letzten staaten . \nals ich vor drei jahren begann , habe ich die meisten von den meisten von den meisten der meisten der meisten der meisten der meisten der meisten der meisten der meisten der meisten der meisten der meisten von heute in der letzten staaten und der letzten staaten . \nals ich vor drei jahren begann , habe ich die meisten von den meisten von den meisten der meisten der meisten der meisten der meisten der meisten der meisten der meisten der meisten der meisten der meisten von heute in der letzten staaten und die meisten der meisten von ihnen \n---------------------------------------------------------------------\n\nExample 5\n\nEnglish : And his brother said, \"I just want to be able to talk to Tony again.\n\nGerman : Und sein Bruder sagte: \"Ich will nur wieder mit Tony reden können.\nGerman Translations generated:\n\nund dann sagte ich : \" ich will nur sein , um sein zu sein . \" \nund dann sagte ich : \" ich will nur sein , um sein zu sein , um zu sein . \nund dann sagte ich : \" ich will nur sein , um sein zu sein , um zu sein . \" \n---------------------------------------------------------------------\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Calculating Bleu Score","metadata":{}},{"cell_type":"code","source":"from torchtext.data.metrics import bleu_score\n\ndef calculate_bleu(data, model, device, max_len=50):\n    tgts = []\n    preds = []\n    for datum in tqdm(data):\n        src = datum['translation'][\"en\"]\n        tgt = datum['translation'][\"de\"]\n        src_idx = torch.tensor(text_transform_eng(src)).unsqueeze(0).to(device)\n        pred_tgt = translate_seq(model, src_idx, device, max_len)\n        pred_tgt = pred_tgt[1:-1]\n        pred_sent = [ger_vocab.get_itos()[i] for i in pred_tgt]\n        preds.append(pred_sent)\n        tgts.append([tokenizer_ger(tgt.lower())])\n\n    return bleu_score(preds, tgts) ","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:45:08.316688Z","iopub.execute_input":"2024-04-24T21:45:08.317513Z","iopub.status.idle":"2024-04-24T21:45:08.326572Z","shell.execute_reply.started":"2024-04-24T21:45:08.317462Z","shell.execute_reply":"2024-04-24T21:45:08.325430Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"bleu = calculate_bleu(test, transformer_model, device)\nprint(\"BLEU Score Achieved :\", bleu)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:45:09.871452Z","iopub.execute_input":"2024-04-24T21:45:09.872228Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  0%|          | 15/8079 [00:06<57:31,  2.34it/s]  ","output_type":"stream"}]}]}